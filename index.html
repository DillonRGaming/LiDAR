<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AR Room Scanner - Passthrough with Overlays</title>
</head>
<body style="margin: 0; overflow: hidden;">
  <script type="module">
    import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.169/build/three.module.js';
    import { ARButton } from 'https://cdn.jsdelivr.net/npm/three@0.169/examples/jsm/webxr/ARButton.js';

    let container, scene, camera, renderer, referenceSpace;
    let pointCloudGeometry, pointCloud;
    const globalPoints = [];  // Accumulate positions
    const maxPoints = 100000;  // Limit to avoid slowdown

    container = document.createElement('div');
    document.body.appendChild(container);

    scene = new THREE.Scene();
    camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.01, 20);

    renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });  // Transparent for camera passthrough
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.xr.enabled = true;
    // No setClearColor needed for AR passthrough (transparent by default)
    container.appendChild(renderer.domElement);

    // Point cloud setup (white points, small size for overlay)
    pointCloudGeometry = new THREE.BufferGeometry();
    pointCloudGeometry.setAttribute('position', new THREE.BufferAttribute(new Float32Array(maxPoints * 3), 3));
    const material = new THREE.PointsMaterial({ color: 0xffffff, size: 0.005, sizeAttenuation: true });  // Smaller, distance-aware
    pointCloud = new THREE.Points(pointCloudGeometry, material);
    scene.add(pointCloud);

    let pointCount = 0;

    // Start AR button (custom label if needed, but default is "AR")
    const button = ARButton.createButton(renderer, {
      requiredFeatures: ['hit-test', 'depth-sensing'],
      depthSensing: { usages: ['cpu-optimized'], format: 'luminance-alpha' },
      domOverlay: { root: document.body }  // Ensures UI overlays work
    });
    button.textContent = 'Start AR';  // Match your button text
    document.body.appendChild(button);

    renderer.xr.addEventListener('sessionstart', async () => {
      console.log('AR session started!');
      referenceSpace = await renderer.xr.getSession().requestReferenceSpace('local');
    });

    renderer.xr.addEventListener('sessionend', () => {
      console.log('AR session ended.');
    });

    function animate() {
      renderer.setAnimationLoop(render);
    }

    function render(timestamp, frame) {
      if (frame && renderer.xr.isPresenting) {
        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          const view = pose.views[0];
          const depthInfo = frame.getDepthInformation(view);

          if (depthInfo) {
            console.log('Depth info available:', depthInfo.width, 'x', depthInfo.height);
            const { width, height, data } = depthInfo;
            const intrinsics = view.projectionMatrix;

            const newPoints = [];
            for (let y = 0; y < height; y += 6) {  // Adjusted downsample for better density/perf
              for (let x = 0; x < width; x += 6) {
                const index = (y * width + x) * 2;
                const depthRaw = data[index] * 256 + data[index + 1];
                const depth = depthRaw / 1000;  // To meters (ARCore scale)

                if (depth > 0.1 && depth < 5) {  // Filter noise/far
                  const nx = (x / width) * 2 - 1;
                  const ny = 1 - (y / height) * 2;
                  const clipW = intrinsics[11] * depth + intrinsics[15];
                  const pointClip = new THREE.Vector4(nx * depth, ny * depth, -depth, clipW);

                  const invProj = new THREE.Matrix4().copy(view.projectionMatrix).invert();
                  const pointView = pointClip.applyMatrix4(invProj);
                  const pointWorld = pointView.applyMatrix4(pose.transform.matrix);

                  newPoints.push(pointWorld.x, pointWorld.y, pointWorld.z);
                }
              }
            }

            if (newPoints.length > 0 && pointCount + newPoints.length / 3 <= maxPoints) {
              globalPoints.push(...newPoints);
              const positions = pointCloudGeometry.attributes.position.array;
              positions.set(globalPoints, 0);
              pointCloudGeometry.attributes.position.needsUpdate = true;
              pointCloudGeometry.setDrawRange(0, globalPoints.length / 3);
              pointCount += newPoints.length / 3;
              console.log('Added points, total:', pointCount);
            }
          } else {
            console.warn('No depth info this frame');
          }

          renderer.render(scene, camera);
        } else {
          console.warn('No pose available');
        }
      }
    }

    animate();

    // Export button
    const exportButton = document.createElement('button');
    exportButton.textContent = 'Export Point Cloud';
    exportButton.style.position = 'absolute';
    exportButton.style.bottom = '20px';
    exportButton.style.left = '20px';
    exportButton.onclick = () => {
      console.log('Exporting ' + pointCount + ' points...');
      // Add export logic here
    };
    document.body.appendChild(exportButton);

    // Error handling for AR session
    button.addEventListener('click', () => {
      console.log('Starting AR...');
    });
  </script>
</body>
</html>